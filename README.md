# this is just a basic scaping project

I deleted some part of the project, but here is a basic one, which does the job!

## usage

best way is to create a virtual environment, activate it, and install the requirements...

enter the `scrape` folder/directory: `cd scrape`\
then run `scrapy crawl scrape`\
(where scrape is the "app" name)\
this will crawl the data and create a database named `scrape.db` (see `pipelines.py` file)

the `database.py` file is unnecessary, but I left in, just to see that one too.

all tags are collected and stored as python list in the database.

### for educational purposes only

--- @dabzse { @mny } ---
